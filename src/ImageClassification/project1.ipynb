{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: MLP Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch count:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eIndex \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch count: \u001b[39m\u001b[38;5;124m\"\u001b[39m, eIndex)\n\u001b[0;32m---> 52\u001b[0m     train_epochloss \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mval_step(model)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(eIndex, train_epochloss, val_acc)\n",
      "File \u001b[0;32m~/codeing/junior/rbe474x/Group5_p4/src/ImageClassification/utils.py:79\u001b[0m, in \u001b[0;36mPipeline.train_step\u001b[0;34m(self, model, optimizer)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m# print('gradients computed')\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 79\u001b[0m     epochloss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epochloss\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lets train a CIFAR10 image classifier\n",
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import networks as net\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "importlib.reload(net)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(num_output_channels=1),  # Convert image to grayscale\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "augmented_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=\"../GeneratedImgs/101/101/\", transform=data_transform\n",
    ")\n",
    "augmented_dataset_loader = torch.utils.data.DataLoader(\n",
    "    augmented_dataset, batch_size=32, num_workers=4, shuffle=True\n",
    ")\n",
    "\n",
    "# WITH DATA AUGMENTATION !!!!!!!!!!!!!!\n",
    "# pass in data loader\n",
    "pipeline = net.Pipeline(synthetic_data_loader=augmented_dataset_loader)\n",
    "# pipeline = net.Pipeline()\n",
    "\n",
    "model = net.CustomMLP().to(pipeline.device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "home_path = os.path.expanduser(\"~\")\n",
    "JOB_FOLDER = os.path.join(home_path, \"outputs/\")\n",
    "TRAINED_MDL_PATH = os.path.join(JOB_FOLDER, \"cifar/mlp/\")\n",
    "\n",
    "import os\n",
    "\n",
    "os.makedirs(JOB_FOLDER, exist_ok=True)\n",
    "os.makedirs(TRAINED_MDL_PATH, exist_ok=True)\n",
    "\n",
    "epochs = 40\n",
    "trainLossList = []\n",
    "valAccList = []\n",
    "for eIndex in range(epochs):\n",
    "    print(\"Epoch count: \", eIndex)\n",
    "    train_epochloss = pipeline.train_step(model, optimizer)\n",
    "    val_acc = pipeline.val_step(model)\n",
    "\n",
    "    print(eIndex, train_epochloss, val_acc)\n",
    "\n",
    "    valAccList.append(val_acc)\n",
    "    trainLossList.append(train_epochloss)\n",
    "\n",
    "    trainedMdlPath = TRAINED_MDL_PATH + f\"{eIndex}.pth\"\n",
    "    torch.save(model.state_dict(), trainedMdlPath)\n",
    "\n",
    "trainLosses = np.array(trainLossList)\n",
    "testAccuracies = np.array(valAccList)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, epochs + 1), trainLosses, label=\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.legend()\n",
    "plt.xticks(range(1, epochs + 1))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "np.savetxt(\"train.log\", trainLosses)\n",
    "np.savetxt(\"test.log\", testAccuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 5: CNN Network Training\n",
    "Train and compare the train loss and validation accuracy against MLP and inbuilt conv layers.\n",
    "\n",
    "Please copy the best checkpoint file in current folder as cnn_custom.pth for automated tests. It is expected to be higher than 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITHOUT DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets train a CIFAR10 image classifier\n",
    "import importlib\n",
    "import torch\n",
    "import numpy as np\n",
    "import networks as net\n",
    "import os\n",
    "\n",
    "importlib.reload(net)\n",
    "\n",
    "# WITHOUT DATA AUGMENTATION !!!!!!!!!!!!!!\n",
    "pipeline = net.Pipeline()\n",
    "model = net.CustomCNN().to(pipeline.device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "home_path = os.path.expanduser(\"~\")\n",
    "JOB_FOLDER = os.path.join(home_path, \"outputs/\")\n",
    "TRAINED_MDL_PATH = os.path.join(JOB_FOLDER, \"cifar/cnn_custom_layer/\")\n",
    "\n",
    "os.makedirs(JOB_FOLDER, exist_ok=True)\n",
    "os.makedirs(TRAINED_MDL_PATH, exist_ok=True)\n",
    "\n",
    "epochs = 40\n",
    "trainLossList = []\n",
    "valAccList = []\n",
    "for eIndex in range(epochs):\n",
    "    # print(\"Epoch count: \", eIndex)\n",
    "\n",
    "    train_epochloss = pipeline.train_step(model, optimizer)\n",
    "    print(\"train complete\")\n",
    "    val_acc = pipeline.val_step(model)\n",
    "\n",
    "    print(eIndex, train_epochloss, val_acc)\n",
    "\n",
    "    valAccList.append(val_acc)\n",
    "    trainLossList.append(train_epochloss)\n",
    "\n",
    "    trainedMdlPath = TRAINED_MDL_PATH + f\"{eIndex}.pth\"\n",
    "    torch.save(model.state_dict(), trainedMdlPath)\n",
    "\n",
    "trainLosses = np.array(trainLossList)\n",
    "testAccuracies = np.array(valAccList)\n",
    "\n",
    "np.savetxt(\"train.log\", trainLosses)\n",
    "np.savetxt(\"test.log\", testAccuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WITH DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets train a CIFAR10 image classifier\n",
    "import importlib\n",
    "import torch\n",
    "import numpy as np\n",
    "import networks as net\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "importlib.reload(net)\n",
    "\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "augmented_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=\"../GeneratedImgs/86/\", transform=data_transform\n",
    ")\n",
    "augmented_dataset_loader = torch.utils.data.DataLoader(\n",
    "    augmented_dataset, batch_size=32, num_workers=4, shuffle=True\n",
    ")\n",
    "\n",
    "# WITH DATA AUGMENTATION !!!!!!!!!!!!!!\n",
    "# pass in data loader\n",
    "pipeline = net.Pipeline(synthetic_data_loader=augmented_dataset_loader)\n",
    "\n",
    "\n",
    "model = net.CustomCNN().to(pipeline.device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "home_path = os.path.expanduser(\"~\")\n",
    "JOB_FOLDER = os.path.join(home_path, \"outputs/\")\n",
    "TRAINED_MDL_PATH = os.path.join(JOB_FOLDER, \"cifar/cnn_custom_layer/\")\n",
    "\n",
    "os.makedirs(JOB_FOLDER, exist_ok=True)\n",
    "os.makedirs(TRAINED_MDL_PATH, exist_ok=True)\n",
    "\n",
    "epochs = 40\n",
    "trainLossList = []\n",
    "valAccList = []\n",
    "for eIndex in range(epochs):\n",
    "    # print(\"Epoch count: \", eIndex)\n",
    "\n",
    "    train_epochloss = pipeline.train_step(model, optimizer)\n",
    "    print(\"train complete\")\n",
    "    val_acc = pipeline.val_step(model)\n",
    "\n",
    "    print(eIndex, train_epochloss, val_acc)\n",
    "\n",
    "    valAccList.append(val_acc)\n",
    "    trainLossList.append(train_epochloss)\n",
    "\n",
    "    trainedMdlPath = TRAINED_MDL_PATH + f\"{eIndex}.pth\"\n",
    "    torch.save(model.state_dict(), trainedMdlPath)\n",
    "\n",
    "trainLosses = np.array(trainLossList)\n",
    "testAccuracies = np.array(valAccList)\n",
    "\n",
    "np.savetxt(\"train.log\", trainLosses)\n",
    "np.savetxt(\"test.log\", testAccuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
